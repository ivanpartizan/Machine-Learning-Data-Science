AI or Artificial Intelligence - it simply means a human intelligence exhibited by machines. AI is a machine that acts like a human.
And currently we have something called narrow AI - that is, machines can be just as good or even better than humans at specific tasks.
But each AI is only good at one task. Narrow AI that we currently have simply means that those machines can only do one thing really well.
They can't be like humans and have multiple abilities. That's called general AI and it's something that we are very, very far away from now.

Machine learning is a subset of AI and machine learning is an approach to try and achieve artificial
intelligence through systems that can find patterns in a set of data.

deep learning or deep neural networks is just one
of the techniques for implementing machine learning.
For now, you can just think of it as a type of algorithm.

data Science simply means analyzing data, looking at data and then doing something with it, usually some
sort of a business goal.
So when we talk about machine learning, there's a lot of overlap with data science.

the only reason that we care about machine learning is that we're able to
use machines to predict results based on incoming data.

Machine learning is using an algorithm or computer program to learn about different patterns in data
and then taking that algorithm and what it's learned to make predictions about the future using similar
data.
ML algorithms are also called models.
machine learning algorithm looks at the input and then
it looks at the output and it tries to figure out the set of instructions
in between these two.
machine models find patterns collected in data so we can use those patterns for future problems.

data analysis is looking at a set of data and gaining an understanding of it by comparing
different examples, different features and making visualizations like graphs
Data science is running experiments on a set of data with the hopes of finding actionable insights within
it.One of these experiments may be to build a machine learning model.

You can consider data analysis and machine learning as a part of data science.

---
MACHINE LEARNING
lets computers make decisions about data 
and lets computers learn from data 
and then make predictions and decisions...

MACHINE LEARNING
is a general term for when computers learn from data, 
it allows computers to do tasks that in the past required humans. 

Machine learning comes in three parts -data collection, data modeling and deployment
We're going to cover data modeling, which means you'll be able to take a data set and apply machine
learning algorithms to find insights on that data

ML FRAMEWORK-six steps
1. Problem definition
What problem are we trying to solve? Supervised, unsupervised, classification, regression?
2. Data
What kind of data do we have?
Structured (rows and columns) or unstructured (like images or audio)?
3. Evaluation
What defines success for us?
4. Features
What features should we model? What do we already know about the data?
A machine learning algorithm's goal is to turn these features into patterns to make predictions.
5. Modelling
Based on our problem and data, what kind of ML model should we use?
6. Experimentation
How could we improve/what can we try next?

When shouldn't you use machine learning?
Will a simple hand-coded instruction based system work?

Main types of ML Problems:
SUPERVISED LEARNING
UNSUPERVISED LEARNING
TRANSFER LEARNING
REINFORCEMENT LEARNING

SUPERVISED LEARNING - you have data and labels
a ML algorithm tries to use the data to predict a label
if it guesses the label wrong, the algorithm corrects itself and tries again
supervised learning algorithm repeats this process over and over again trying to get better

Main types of supervised learning:
Classification and regression

Classification: 
involves predicting if something is one thing or another
If there are only two options, it is called binary classification
If there are more than two options, it is called multi-class classification

Regression:
involves problems trying to predict the number
"how much will this house sell for?"
"how many people will buy this app?"

UNSUPERVISED LEARNING - has data but no labels
you find patterns in the data and group customers (who purchase similar things together)
you provided the labels, they were not there to begin with but the patterns were
clusters - putting groups of similar examples together

TRANSFER LEARNING - leverages what one machine learning model has learned in another
machine learning model

REINFORCEMENT LEARNING - involves having a computer program performs some actions 
within a defined space and rewarding it for doing it well
or punishing it for doing poorly
example: teaching a ML algorithm to play chess

SUPERVISED LEARNING - 'I know my inputs and outputs'
UNSUPERVISED LEARNING - 'I am not sure of the outputs but I have inputs'
TRANSFER LEARNING - 'I think my problem may be similar to something else'

DATA
Different types of data:
STRUCTURED and UNSTRUCTURED

STRUCTURED data: Excel file, rows and columns
all of the samples are typically in similar format
UNSTRUCTURED data: images, natural text, videos and audio files

STATIC and STREAMING DATA
STATIC is data which doesn't change over time (CSV files)
STREAMING is data which is constantly changed over time

'The more data the better'

A data science workflow:
opening the CSV file in Jupyter notebook, a tool for building ML projects
exploring the data and performing data analysis using pandas, a Python library for data analysis
making visualisations such as graphs and comparing different data points using matplotlib, 
then building ML models on the data using scikit learn

EVALUATION
Every ML problem you come across will have the similar goal of finding insights in data 
to predict the future in some way
An evaluation metric is measure of how well ML algorithm predicts the future

Different types of metrics:
- for classification, or predicting whether some thing is one thing or another - accuracy, precision, recall
- for regression, or predicting a number (example, how much a car will sell for) - Mean absolute error 
or MAE, Mean squared error or MSE, root mean squared error of RMSE
- for recommendation problems: precision at K

FEATURES
Features is another word for different forms of data (different forms of data within structured or 
unstructured data)
Different features of data, example: weight, sex, heart rate, chest pain
Features could also be referred to as feature variables
We want to use feature variables to predict the target variable (example: heart disease?)

There are different kinds of feature variables:
numerical features (a number) and categorical features (one thing or another, like sex)
And then there is derived feature, which is when someone looks at the data and 
creates a new feature using the existing ones
It is often referred to as feature engineering - (process of) looking at different features of data and 
creating new ones/altering existing ones

A feature works best within ML algorithm if many of the samples have it

Feature coverage - how many samples have different features? Ideally, every sample has the same features. 
The process of ensuring all samples have similar information is called feature coverage.

MODELLING
3 SETS
Based on our problem and data, what ML model should we use?

Modelling can be broken down into three parts:
1. Choosing and training a model
2. Tuning a model
3. Model comparison

KEY - The most important concept in machine learning:
(the training, validation and test sets or 3 sets)
Split your data into 3 different sets:
1. Training set (train your model on this)
2. Validation set (tune your model on this)
3. Test set (test and compare your different models on this)

Example, exam: course materials (training set) -> practice exam (validation set) -> final exam (test set)
Generalization - the ability for a machine learning model to perform well on data it hasn't seen before

training split 70-80%
validation split 10-15%
test split 10-15%
All three of these sets are separate! During training, a model never sees a validation split or a test split
And during testing, you are doing it on a test split, not a training set

Modelling - Picking the model
1. Choosing and training a model - training data
2. Tuning a model - validation data
3. Model comparison - test data

Choosing a model:
There are many pre built ML models
Main goal would be knowing what kind of ML algorithm to use with what kind of problem

If you are working with structured data, decision trees such as Random Forest and 
gradient boosting algorithms like CatBoost and XGBoost tend to work best
If you are working with unstructured data, Deep Learning, neural networks and 
Transfer Learning tend to work best

after choosing a model, next step is to train it

Training a model - main goal will be to line up inputs and outputs
we want our model to look at a feature variables, the inputs, 
and then find the patterns and use them to predict the target variable
- another common naming setting is to use x (data) to predict y (labels)
Training a model takes place on the training data split (model learns the course material)
Goal: Minimise time between experiments

Things to remember!
- some models work better than others on different problems
- don't be afraid to try things (ML is highly iterative process)
- start small and build up (add complexity) as you need

Modelling - Tuning
Model can be tuned with different types of data, usually tuning will take place on a validation data split
Depending on what kind of model you are using will depend on what kind of hyper parameters you can choose
For example, a Random Forest will allow you to adjust the number of trees
and a Neural Network will allow you to adjust the number of layers
- examples of different hyper parameters you can adjust on different kinds of algorithms.

Things to remember!
- machine learning models have hyperparameters you can adjust
(however, depending on what model you are going to use, the hyperparameters will be different)
A goal of tuning hyperparameters is to improve your model's performance
- a models first results are not its last
- tuning can take place on training or validation data sets

Modelling - Comparison
How will our model perform in the real world?

After you have tuned and improved your model's performance through hyperparameter tuning, 
it is time to see how it performs on the test set 
(test set is like the final exam for machine learning models).
If you have created your data splits correctly, 
it should give you an indication on how your model will perform once deployed in production. 

A good model will yield similar results on the training, validation and test sets, 
and it is not uncommon to see a slight decline in performance from the model 
on the training and validation set to the test set.

What you should be worried about is 
if the training set performance is dramatically higher than the test set, also known as underfitting, 
and if the test set performance is higher than the training set performance, also known as overfiting.

Overfitting and Underfitting are both examples of a model not being able to generalize well, 
which is what we don't want.
The ideal model shows up in the Goldilocks zone (balanced).
It fits just right, not too well, but not too poorly. Finding this balanced zone is an iterative process. 

There are several reasons why underfitting and overfitting can happen, but the main ones are: 
data leakage and data mismatch.

Data leakage happens when some of your test data leaks into your training data, and 
this often results in overfitting or a model doing better on the test set than on the training data set.

It is like if you were to have a look at the final exam or everyone had to look at the final exam 
as the practice exam, your machine learning model has just learned what it is about to be test on.
The test data set is used as an indication of how well your model will generalize in the real world 
so you want to avoid data leakage. 

Data mismatch happens when the data you are testing on is different to the data you are training on,
such as having different features in the training data to the test data.
Having this kind of mismatch can lead to models performing poorly on test data compared to training
data (underfitting).

This is why it is important to ensure that training is done on the same kind of data as 
you will be testing on and as close as possible to what you will be using in your future applications.

FIXES for OVERFITTING and UNDERFITTING
OVERFITTING:
collect more data
(more data will provide more potential patterns for a model to find and 
thus lower the potential for it to find them all)
try a less advanced model
UNDERFITTING:
try a more advanced model
increase model hyperparameters
reduce amount of features
train longer

Finally, when comparing two different models to each other, it is important to ensure 
you are comparing apples with apples and oranges with oranges.
During comparison, you want to make sure you take into account not only the final result, 
but what it took to get there (prediction time, not only accuracy).

Things to remember!
- want to avoid overfitting and underfitting (head towards generality)
- keep the test set separate at all costs
(when you split your data, you want to have a training set and then throw away the test data set and
lock it up; and once your model has been trained, then you can open up the test data set, 
you can unlock it, take it out of the safe and see how your model performs)
- compare apples to apples
(have model 1 and model 2 on data set 1 and data set 1)
- one best performance metric does not equal best model
(example, you may be optimizing for prediction time, 
so although a model that makes a faster prediction doesn't get as high accuracy as another model,
that takes a little bit longer, it might not matter to you because you need something that 
can predict as fast as possible)

Step 6
EXPERIMENTATION
All of these six steps here are a highly iterative process, 
meaning you might try one thing, find out it doesn't work, then try another, another and another and just keep going through this loop.
With a process like the one here, machine learning projects become tool matching projects. 
We are going to use this process and learn the different tools for each step. 

Defining a problem within is step one. Steps two, three and four are called data analysis. 
Once you know a little bit more about the data, you decide to build a machine learning model 
using the features you found to predict some target. And this is step five.
Your first model goes well. You have matched the model to the problem and it is producing some good outputs. 
So you decide to report what you found. And after your initial report, 
your project manager asked to see if the model can be improved to get better results.
So you do your research and find there is another approach you can take.
This is step six - experiment.

You might try a different model, model two, and see how it goes. 
You might try vary the input slightly and change your desired outputs and try a new model. 

TOOLS WE WILL USE
Anaconda - which is like the hardware store of data science and machine learning tools.
For data analysis (steps: data,evaluation,features) - pandas, matplotlib, NumPy
For building ML models (step:modelling) - TensorFlow, PyTorch, scikit learn, XGBoost, CatBoost

to write Python code and communicating our work, we are going to be using jupyter notebooks.
----
PANDAS-data analysis library
is used to explore data, analyze data, manipulate data, get it ready for machine learning.
WHY PANDAS?
-simple to use
-integrated with many other data science and ML Python tools
-helps you get your data ready for machine learning

NUMPY
is basically the backbone of all data science, machine learning and numerical computing
in Python.
It stands for numerical python.
in all of machine learning, no matter what kind of data that you're working with, 
NumPy is going to form the foundation of turning your data into a series of numbers.
And then what a machine learning algorithm will do is work out the patterns in those numbers.
machine learning, although it's referred to as modeling, is essentially taking data, 
turning it into numbers And in this case with NumPy, usually the form of a numpy array, 
and then finding patterns in those numbers.

WHY NUMPY?
-it is fast
-behind the scenes optimizations written in C
-vectorization via broadcasting (avoiding loops)
-backbone of other Python scientific packages

MATPLOTLIB
it's a plotting library, more specifically a python plotting library.
It allows us to turn our data into some pretty visualizations, also known
as plots or figures.

WHY MATPLOTLIB?
-built on NumPy arrays (and Python)
-integrates directly with pandas
-can create basic or advanced plots
-simple to use interface once you get the foundations

SCIKIT-LEARN(sklearn)
Scikit Learn is a python machine learning library, which means that if we have data,
SKlearn helps us build machine learning models to make predictions or learn patterns within that
data and then make predictions.And it also implements tools to help us evaluate those predictions.
Are they good or are they bad? Are they worth holding on to? Could we put them into our application and actually use them?

Why scikit-learn?
-built on NumPy and Matplotlib(and Python)
-has many in-built machine learning models
-methods to evaluate such machine learning models
-very well-designed API

scikit-learn workflow
1. get data ready
2. pick a model(to suit your problem)
3.fit the model (find patterns within the data-learning patterns) to the data and make a predition (using patterns)
4. evaluate the model
5.improve through experimentation
6.save and reload your trained model
